#!/usr/bin/env python3
"""Add Chicago localization filter and re-analyze."""
import sqlite3
import json
import re

def main():
    conn = sqlite3.connect("data/processed.db")
    cursor = conn.cursor()

    # Get all relevant questions
    cursor.execute("""
        SELECT id, source, group_name, text_preview, url, classification
        FROM processed_items
        WHERE classification IS NOT NULL
        ORDER BY processed_at DESC
    """)

    items = cursor.fetchall()

    # Chicago-related keywords
    chicago_keywords = [
        'chicago',
        'schaumburg',  # Liberum Law location
        'illinois',
        'il ',
        ' il,',
        'chicagoland',
        'cook county',
        'naperville',
        'aurora',
        'joliet',
        'rockford',
        'evanston',
        'arlington heights',
    ]

    all_questions = []
    chicago_questions = []
    non_chicago_immigration_questions = []

    for item in items:
        item_id, source, group_name, text_preview, url, classification_json = item

        if not classification_json:
            continue

        classification = json.loads(classification_json)
        is_relevant = classification.get('is_relevant', False)
        is_question = classification.get('is_question', False)

        if not (is_relevant and is_question):
            continue

        text_lower = text_preview.lower()
        title = text_preview.split('\n')[0]

        # Check if Chicago-related
        is_chicago = any(kw in text_lower for kw in chicago_keywords)

        # Skip false positives from r/chicago that are not immigration-related
        if group_name == 'chicago':
            # Must have strong immigration keywords
            immigration_keywords = [
                'visa', 'green card', 'greencard', 'h1b', 'h-1b',
                'immigration', 'uscis', 'citizenship', 'asylum',
                'deportation', 'i-485', 'i-130', 'naturalization'
            ]
            has_immigration = any(kw in text_lower for kw in immigration_keywords)

            if not has_immigration:
                continue  # Skip non-immigration posts from r/chicago

        post_data = {
            'id': item_id,
            'title': title[:150],
            'group': group_name,
            'url': url,
            'text': text_preview,
            'category': classification.get('category', 'other'),
            'is_chicago': is_chicago
        }

        all_questions.append(post_data)

        if is_chicago:
            chicago_questions.append(post_data)
        elif group_name != 'chicago':  # Immigration question but not Chicago-related
            non_chicago_immigration_questions.append(post_data)

    conn.close()

    # Print results
    print(f"\n{'='*90}")
    print(f"üìç –ê–ù–ê–õ–ò–ó –° –õ–û–ö–ê–õ–ò–ó–ê–¶–ò–ï–ô –ü–û –ß–ò–ö–ê–ì–û")
    print(f"{'='*90}\n")

    print(f"–í—Å–µ–≥–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤: {len(all_questions)}")
    print(f"üèôÔ∏è  –£–ø–æ–º–∏–Ω–∞—é—Ç –ß–∏–∫–∞–≥–æ/–ò–ª–ª–∏–Ω–æ–π—Å: {len(chicago_questions)} ({len(chicago_questions)*100//len(all_questions) if all_questions else 0}%)")
    print(f"üåé –î—Ä—É–≥–∏–µ –ª–æ–∫–∞—Ü–∏–∏/–Ω–µ —É–∫–∞–∑–∞–Ω–æ: {len(non_chicago_immigration_questions)}\n")

    # Show Chicago questions
    if chicago_questions:
        print(f"{'='*90}")
        print(f"üèôÔ∏è  –í–û–ü–†–û–°–´ –ü–†–û –ß–ò–ö–ê–ì–û/–ò–õ–õ–ò–ù–û–ô–° ({len(chicago_questions)} —à—Ç.)")
        print(f"{'='*90}\n")

        for i, q in enumerate(chicago_questions, 1):
            print(f"{i}. [{q['category'].upper()}] r/{q['group']}")
            print(f"   {q['title']}")
            print(f"   üîó {q['url']}")

            # Show where Chicago was mentioned
            text_lower = q['text'].lower()
            for kw in chicago_keywords:
                if kw in text_lower:
                    # Find context
                    idx = text_lower.find(kw)
                    start = max(0, idx - 50)
                    end = min(len(text_lower), idx + 50)
                    context = q['text'][start:end].replace('\n', ' ')
                    print(f"   üí¨ ...{context}...")
                    break
            print()

    # Statistics for Liberum Law
    print(f"\n{'='*90}")
    print(f"üíº –î–õ–Ø LIBERUM LAW (–æ—Ñ–∏—Å –≤ Schaumburg, IL)")
    print(f"{'='*90}\n")

    # Liberum can work with all US clients (remotely) but Chicago is priority
    liberum_fit_chicago = len(chicago_questions) * 0.68  # 68% fit rate
    liberum_fit_total = len(all_questions) * 0.68

    print(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –¢–û–õ–¨–ö–û –ª–æ–∫–∞–ª—å–Ω—ã–µ (–ß–∏–∫–∞–≥–æ) –∫–ª–∏–µ–Ω—Ç—ã")
    print(f"  –í–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ –ß–∏–∫–∞–≥–æ –∑–∞ 3 –¥–Ω—è: {len(chicago_questions)}")
    print(f"  –ü–æ–¥—Ö–æ–¥—è—Ç –¥–ª—è Liberum: ~{int(liberum_fit_chicago)}")
    print(f"  –í –¥–µ–Ω—å: ~{liberum_fit_chicago/3:.1f} –ª–∏–¥–æ–≤")
    print(f"  –í –º–µ—Å—è—Ü: ~{liberum_fit_chicago/3*30:.0f} –ª–∏–¥–æ–≤\n")

    print(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –í–°–ï –°–®–ê (—É–¥–∞–ª–µ–Ω–Ω–æ)")
    print(f"  –í—Å–µ–≥–æ –≤–æ–ø—Ä–æ—Å–æ–≤ –∑–∞ 3 –¥–Ω—è: {len(all_questions)}")
    print(f"  –ü–æ–¥—Ö–æ–¥—è—Ç –¥–ª—è Liberum: ~{int(liberum_fit_total)}")
    print(f"  –í –¥–µ–Ω—å: ~{liberum_fit_total/3:.1f} –ª–∏–¥–æ–≤")
    print(f"  –í –º–µ—Å—è—Ü: ~{liberum_fit_total/3*30:.0f} –ª–∏–¥–æ–≤\n")

    print(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: –ü–†–ò–û–†–ò–¢–ï–¢ –ß–∏–∫–∞–≥–æ + –æ—Å—Ç–∞–ª—å–Ω—ã–µ –°–®–ê")
    print(f"  –ß–∏–∫–∞–≥–æ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1): ~{liberum_fit_chicago/3:.1f} –ª–∏–¥–æ–≤/–¥–µ–Ω—å")
    print(f"  –û—Å—Ç–∞–ª—å–Ω—ã–µ –°–®–ê (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2): ~{(liberum_fit_total-liberum_fit_chicago)/3:.1f} –ª–∏–¥–æ–≤/–¥–µ–Ω—å")
    print(f"  –ò–¢–û–ì–û: ~{liberum_fit_total/3:.1f} –ª–∏–¥–æ–≤/–¥–µ–Ω—å\n")

    # Save to file
    with open("chicago_analysis.txt", "w", encoding="utf-8") as f:
        f.write(f"–ê–ù–ê–õ–ò–ó –° –õ–û–ö–ê–õ–ò–ó–ê–¶–ò–ï–ô –ü–û –ß–ò–ö–ê–ì–û\n")
        f.write(f"{'='*90}\n\n")

        f.write(f"–í—Å–µ–≥–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {len(all_questions)}\n")
        f.write(f"–£–ø–æ–º–∏–Ω–∞—é—Ç –ß–∏–∫–∞–≥–æ: {len(chicago_questions)}\n\n")

        f.write(f"–í–û–ü–†–û–°–´ –ü–†–û –ß–ò–ö–ê–ì–û:\n")
        f.write(f"{'='*90}\n\n")

        for i, q in enumerate(chicago_questions, 1):
            f.write(f"{i}. [{q['category'].upper()}] r/{q['group']}\n")
            f.write(f"   {q['title']}\n")
            f.write(f"   {q['url']}\n\n")

    print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: chicago_analysis.txt\n")

if __name__ == "__main__":
    main()
